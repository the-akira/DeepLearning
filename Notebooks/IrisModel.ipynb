{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo e Salvando um Modelo\n",
    "\n",
    "Utilizando o conjunto de dados das [Flores Iris](https://archive.ics.uci.edu/ml/datasets/iris)\n",
    "\n",
    "Iniciamos importando as bibliotecas básicas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos e observamos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('Dados/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável **X** são as features que utilizaremos para prever a respectiva flor.\n",
    "\n",
    "Eliminamos a coluna 'species', que é nosso *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável **y** é o nosso *target*, a espécie da flor que desejamos prever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    setosa\n",
       "1    setosa\n",
       "2    setosa\n",
       "3    setosa\n",
       "4    setosa\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função **unique()** nos retorna os valores únicos da coluna **y**\n",
    "\n",
    "Estamos lidando com 3 espécies:\n",
    "\n",
    "- setosa\n",
    "- versicolor\n",
    "- virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora utilizar o **LabelBinarizer** para codificar cada espécie\n",
    "\n",
    "Setosa por exemplo será **[1, 0, 0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = encoder.fit_transform(y)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos os dados em Train/Test\n",
    "\n",
    "E utilizamos o **MinMaxScaler** para fazer o *scaling* dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construímos o nosso Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamos o nosso Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 1.2999 - accuracy: 0.2333 - val_loss: 1.2575 - val_accuracy: 0.2333\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2920 - accuracy: 0.2250 - val_loss: 1.2531 - val_accuracy: 0.2333\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.2832 - accuracy: 0.2250 - val_loss: 1.2489 - val_accuracy: 0.2333\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.2755 - accuracy: 0.2250 - val_loss: 1.2448 - val_accuracy: 0.2333\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.2681 - accuracy: 0.2250 - val_loss: 1.2410 - val_accuracy: 0.2333\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2605 - accuracy: 0.2250 - val_loss: 1.2371 - val_accuracy: 0.2333\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2534 - accuracy: 0.2250 - val_loss: 1.2335 - val_accuracy: 0.2333\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.2468 - accuracy: 0.2167 - val_loss: 1.2301 - val_accuracy: 0.2333\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.2396 - accuracy: 0.2167 - val_loss: 1.2268 - val_accuracy: 0.2333\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2333 - accuracy: 0.2083 - val_loss: 1.2235 - val_accuracy: 0.2333\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2266 - accuracy: 0.2000 - val_loss: 1.2202 - val_accuracy: 0.2333\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2201 - accuracy: 0.2167 - val_loss: 1.2169 - val_accuracy: 0.2667\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2140 - accuracy: 0.2167 - val_loss: 1.2137 - val_accuracy: 0.2000\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2075 - accuracy: 0.2667 - val_loss: 1.2103 - val_accuracy: 0.2333\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.2016 - accuracy: 0.3250 - val_loss: 1.2069 - val_accuracy: 0.3000\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.1958 - accuracy: 0.3500 - val_loss: 1.2036 - val_accuracy: 0.3000\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2089 - accuracy: 0.28 - 0s 41ms/step - loss: 1.1904 - accuracy: 0.3250 - val_loss: 1.2003 - val_accuracy: 0.3000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1852 - accuracy: 0.3583 - val_loss: 1.1971 - val_accuracy: 0.3000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1799 - accuracy: 0.3583 - val_loss: 1.1938 - val_accuracy: 0.3000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1748 - accuracy: 0.3417 - val_loss: 1.1907 - val_accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1695 - accuracy: 0.3417 - val_loss: 1.1875 - val_accuracy: 0.3333\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1644 - accuracy: 0.3333 - val_loss: 1.1842 - val_accuracy: 0.3000\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.1596 - accuracy: 0.3333 - val_loss: 1.1811 - val_accuracy: 0.3000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1549 - accuracy: 0.3417 - val_loss: 1.1780 - val_accuracy: 0.3000\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1502 - accuracy: 0.3417 - val_loss: 1.1750 - val_accuracy: 0.2667\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1453 - accuracy: 0.3417 - val_loss: 1.1719 - val_accuracy: 0.2667\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1407 - accuracy: 0.3417 - val_loss: 1.1686 - val_accuracy: 0.2667\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1362 - accuracy: 0.3500 - val_loss: 1.1652 - val_accuracy: 0.2667\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.1316 - accuracy: 0.3500 - val_loss: 1.1621 - val_accuracy: 0.2667\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.1270 - accuracy: 0.3500 - val_loss: 1.1588 - val_accuracy: 0.2667\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1226 - accuracy: 0.3500 - val_loss: 1.1555 - val_accuracy: 0.2667\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1182 - accuracy: 0.3500 - val_loss: 1.1523 - val_accuracy: 0.2667\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1139 - accuracy: 0.3500 - val_loss: 1.1490 - val_accuracy: 0.2667\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.1096 - accuracy: 0.3500 - val_loss: 1.1457 - val_accuracy: 0.2667\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.1052 - accuracy: 0.3500 - val_loss: 1.1426 - val_accuracy: 0.2667\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1010 - accuracy: 0.3500 - val_loss: 1.1395 - val_accuracy: 0.2667\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0968 - accuracy: 0.3500 - val_loss: 1.1362 - val_accuracy: 0.3000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0926 - accuracy: 0.3500 - val_loss: 1.1330 - val_accuracy: 0.3000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0885 - accuracy: 0.3500 - val_loss: 1.1298 - val_accuracy: 0.3000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0844 - accuracy: 0.3500 - val_loss: 1.1268 - val_accuracy: 0.3000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0802 - accuracy: 0.3500 - val_loss: 1.1234 - val_accuracy: 0.3000\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0762 - accuracy: 0.3500 - val_loss: 1.1200 - val_accuracy: 0.3000\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0721 - accuracy: 0.3500 - val_loss: 1.1165 - val_accuracy: 0.3000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0681 - accuracy: 0.3500 - val_loss: 1.1132 - val_accuracy: 0.3000\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0641 - accuracy: 0.3500 - val_loss: 1.1100 - val_accuracy: 0.3000\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0602 - accuracy: 0.3500 - val_loss: 1.1067 - val_accuracy: 0.3000\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0563 - accuracy: 0.3500 - val_loss: 1.1031 - val_accuracy: 0.3000\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0524 - accuracy: 0.3583 - val_loss: 1.0999 - val_accuracy: 0.3000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0486 - accuracy: 0.3583 - val_loss: 1.0967 - val_accuracy: 0.3000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0446 - accuracy: 0.3583 - val_loss: 1.0932 - val_accuracy: 0.3000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.0408 - accuracy: 0.3583 - val_loss: 1.0898 - val_accuracy: 0.3000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0371 - accuracy: 0.3667 - val_loss: 1.0867 - val_accuracy: 0.3000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0330 - accuracy: 0.3750 - val_loss: 1.0833 - val_accuracy: 0.3000\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0294 - accuracy: 0.3750 - val_loss: 1.0799 - val_accuracy: 0.3000\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0253 - accuracy: 0.3750 - val_loss: 1.0765 - val_accuracy: 0.3000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0216 - accuracy: 0.3750 - val_loss: 1.0731 - val_accuracy: 0.3000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0179 - accuracy: 0.3750 - val_loss: 1.0695 - val_accuracy: 0.3000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0139 - accuracy: 0.3833 - val_loss: 1.0661 - val_accuracy: 0.3000\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0102 - accuracy: 0.3833 - val_loss: 1.0624 - val_accuracy: 0.3333\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0063 - accuracy: 0.4000 - val_loss: 1.0589 - val_accuracy: 0.3667\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0025 - accuracy: 0.4000 - val_loss: 1.0553 - val_accuracy: 0.4000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9986 - accuracy: 0.4000 - val_loss: 1.0517 - val_accuracy: 0.4000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.9947 - accuracy: 0.4083 - val_loss: 1.0482 - val_accuracy: 0.4000\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9909 - accuracy: 0.4250 - val_loss: 1.0444 - val_accuracy: 0.4000\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9871 - accuracy: 0.4417 - val_loss: 1.0408 - val_accuracy: 0.4000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9832 - accuracy: 0.4500 - val_loss: 1.0373 - val_accuracy: 0.4000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9792 - accuracy: 0.4500 - val_loss: 1.0337 - val_accuracy: 0.4000\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9753 - accuracy: 0.4583 - val_loss: 1.0301 - val_accuracy: 0.4000\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.9715 - accuracy: 0.4583 - val_loss: 1.0268 - val_accuracy: 0.4000\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9676 - accuracy: 0.4667 - val_loss: 1.0232 - val_accuracy: 0.4000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.9636 - accuracy: 0.4667 - val_loss: 1.0196 - val_accuracy: 0.4000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9596 - accuracy: 0.4750 - val_loss: 1.0159 - val_accuracy: 0.4000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9558 - accuracy: 0.4833 - val_loss: 1.0123 - val_accuracy: 0.4000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9518 - accuracy: 0.4917 - val_loss: 1.0085 - val_accuracy: 0.4000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9478 - accuracy: 0.5167 - val_loss: 1.0050 - val_accuracy: 0.4000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9438 - accuracy: 0.5250 - val_loss: 1.0014 - val_accuracy: 0.4000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9399 - accuracy: 0.5500 - val_loss: 0.9977 - val_accuracy: 0.4000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9358 - accuracy: 0.5667 - val_loss: 0.9940 - val_accuracy: 0.4333\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9317 - accuracy: 0.5833 - val_loss: 0.9903 - val_accuracy: 0.4667\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9277 - accuracy: 0.5917 - val_loss: 0.9867 - val_accuracy: 0.4667\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9238 - accuracy: 0.5917 - val_loss: 0.9831 - val_accuracy: 0.4667\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9196 - accuracy: 0.6000 - val_loss: 0.9793 - val_accuracy: 0.4667\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9156 - accuracy: 0.6083 - val_loss: 0.9755 - val_accuracy: 0.4667\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.9118 - accuracy: 0.6167 - val_loss: 0.9717 - val_accuracy: 0.4667\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9075 - accuracy: 0.6333 - val_loss: 0.9680 - val_accuracy: 0.5000\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9037 - accuracy: 0.6333 - val_loss: 0.9646 - val_accuracy: 0.5000\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.8993 - accuracy: 0.6417 - val_loss: 0.9607 - val_accuracy: 0.5000\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.8953 - accuracy: 0.6500 - val_loss: 0.9568 - val_accuracy: 0.5000\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8912 - accuracy: 0.6500 - val_loss: 0.9531 - val_accuracy: 0.5333\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8871 - accuracy: 0.6500 - val_loss: 0.9494 - val_accuracy: 0.5333\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8830 - accuracy: 0.6500 - val_loss: 0.9455 - val_accuracy: 0.5667\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8791 - accuracy: 0.6500 - val_loss: 0.9418 - val_accuracy: 0.5667\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8748 - accuracy: 0.6583 - val_loss: 0.9379 - val_accuracy: 0.5667\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8705 - accuracy: 0.6583 - val_loss: 0.9340 - val_accuracy: 0.5667\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8665 - accuracy: 0.6667 - val_loss: 0.9299 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8623 - accuracy: 0.6750 - val_loss: 0.9261 - val_accuracy: 0.6000\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8581 - accuracy: 0.6750 - val_loss: 0.9221 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8540 - accuracy: 0.6750 - val_loss: 0.9183 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8500 - accuracy: 0.6750 - val_loss: 0.9142 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8458 - accuracy: 0.6750 - val_loss: 0.9103 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8416 - accuracy: 0.6833 - val_loss: 0.9065 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8375 - accuracy: 0.6833 - val_loss: 0.9027 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8334 - accuracy: 0.6833 - val_loss: 0.8986 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8293 - accuracy: 0.6833 - val_loss: 0.8949 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8251 - accuracy: 0.6833 - val_loss: 0.8911 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8211 - accuracy: 0.6833 - val_loss: 0.8873 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8170 - accuracy: 0.6833 - val_loss: 0.8834 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8129 - accuracy: 0.6833 - val_loss: 0.8796 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8089 - accuracy: 0.6833 - val_loss: 0.8757 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8048 - accuracy: 0.6833 - val_loss: 0.8717 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8007 - accuracy: 0.6833 - val_loss: 0.8679 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7969 - accuracy: 0.6833 - val_loss: 0.8641 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7927 - accuracy: 0.6833 - val_loss: 0.8603 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7888 - accuracy: 0.6833 - val_loss: 0.8564 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7848 - accuracy: 0.6833 - val_loss: 0.8524 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7808 - accuracy: 0.6833 - val_loss: 0.8483 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7767 - accuracy: 0.6833 - val_loss: 0.8445 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7728 - accuracy: 0.6833 - val_loss: 0.8406 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7688 - accuracy: 0.6833 - val_loss: 0.8367 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7649 - accuracy: 0.6833 - val_loss: 0.8329 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7610 - accuracy: 0.6833 - val_loss: 0.8291 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7570 - accuracy: 0.6833 - val_loss: 0.8253 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7531 - accuracy: 0.6833 - val_loss: 0.8212 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7493 - accuracy: 0.6833 - val_loss: 0.8172 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7454 - accuracy: 0.6833 - val_loss: 0.8135 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7415 - accuracy: 0.6833 - val_loss: 0.8097 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7377 - accuracy: 0.6833 - val_loss: 0.8060 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7340 - accuracy: 0.6833 - val_loss: 0.8022 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7300 - accuracy: 0.6833 - val_loss: 0.7983 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7263 - accuracy: 0.6833 - val_loss: 0.7945 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7227 - accuracy: 0.6833 - val_loss: 0.7909 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7189 - accuracy: 0.6833 - val_loss: 0.7873 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7152 - accuracy: 0.6833 - val_loss: 0.7834 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7115 - accuracy: 0.6833 - val_loss: 0.7797 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7080 - accuracy: 0.6833 - val_loss: 0.7759 - val_accuracy: 0.6000\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7043 - accuracy: 0.6833 - val_loss: 0.7724 - val_accuracy: 0.6000\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7007 - accuracy: 0.6833 - val_loss: 0.7689 - val_accuracy: 0.6000\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6971 - accuracy: 0.6833 - val_loss: 0.7654 - val_accuracy: 0.6000\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6936 - accuracy: 0.6833 - val_loss: 0.7619 - val_accuracy: 0.6000\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6902 - accuracy: 0.6833 - val_loss: 0.7583 - val_accuracy: 0.6000\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6866 - accuracy: 0.6833 - val_loss: 0.7549 - val_accuracy: 0.6000\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6832 - accuracy: 0.6833 - val_loss: 0.7516 - val_accuracy: 0.6000\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6797 - accuracy: 0.6833 - val_loss: 0.7482 - val_accuracy: 0.6000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6764 - accuracy: 0.6833 - val_loss: 0.7447 - val_accuracy: 0.6000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6730 - accuracy: 0.6833 - val_loss: 0.7411 - val_accuracy: 0.6000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.6833 - val_loss: 0.7376 - val_accuracy: 0.6000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6662 - accuracy: 0.6833 - val_loss: 0.7341 - val_accuracy: 0.6000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6630 - accuracy: 0.6833 - val_loss: 0.7307 - val_accuracy: 0.6000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6597 - accuracy: 0.6833 - val_loss: 0.7272 - val_accuracy: 0.6000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6563 - accuracy: 0.6833 - val_loss: 0.7237 - val_accuracy: 0.6000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6531 - accuracy: 0.6833 - val_loss: 0.7202 - val_accuracy: 0.6000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6500 - accuracy: 0.6833 - val_loss: 0.7166 - val_accuracy: 0.6000\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6469 - accuracy: 0.6833 - val_loss: 0.7130 - val_accuracy: 0.6000\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6437 - accuracy: 0.6917 - val_loss: 0.7097 - val_accuracy: 0.6000\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6405 - accuracy: 0.6917 - val_loss: 0.7067 - val_accuracy: 0.6000\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6374 - accuracy: 0.6917 - val_loss: 0.7033 - val_accuracy: 0.6000\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6345 - accuracy: 0.6917 - val_loss: 0.6999 - val_accuracy: 0.6000\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6313 - accuracy: 0.6917 - val_loss: 0.6968 - val_accuracy: 0.6000\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6283 - accuracy: 0.6917 - val_loss: 0.6937 - val_accuracy: 0.6000\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6253 - accuracy: 0.6917 - val_loss: 0.6907 - val_accuracy: 0.6000\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6223 - accuracy: 0.6917 - val_loss: 0.6877 - val_accuracy: 0.6000\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6194 - accuracy: 0.6917 - val_loss: 0.6849 - val_accuracy: 0.6000\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6166 - accuracy: 0.6917 - val_loss: 0.6816 - val_accuracy: 0.6333\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6135 - accuracy: 0.6917 - val_loss: 0.6786 - val_accuracy: 0.6333\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6108 - accuracy: 0.6917 - val_loss: 0.6756 - val_accuracy: 0.6333\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6079 - accuracy: 0.6917 - val_loss: 0.6724 - val_accuracy: 0.6333\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6050 - accuracy: 0.6917 - val_loss: 0.6695 - val_accuracy: 0.6333\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6025 - accuracy: 0.7000 - val_loss: 0.6662 - val_accuracy: 0.6333\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5995 - accuracy: 0.7000 - val_loss: 0.6633 - val_accuracy: 0.6333\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5967 - accuracy: 0.7000 - val_loss: 0.6603 - val_accuracy: 0.6333\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5940 - accuracy: 0.7000 - val_loss: 0.6575 - val_accuracy: 0.6333\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5914 - accuracy: 0.7000 - val_loss: 0.6545 - val_accuracy: 0.6667\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5887 - accuracy: 0.7000 - val_loss: 0.6515 - val_accuracy: 0.6667\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5861 - accuracy: 0.7167 - val_loss: 0.6485 - val_accuracy: 0.6667\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5835 - accuracy: 0.7167 - val_loss: 0.6455 - val_accuracy: 0.6667\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.7167 - val_loss: 0.6427 - val_accuracy: 0.6667\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5783 - accuracy: 0.7167 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5758 - accuracy: 0.7333 - val_loss: 0.6372 - val_accuracy: 0.6667\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5733 - accuracy: 0.7333 - val_loss: 0.6346 - val_accuracy: 0.6667\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5708 - accuracy: 0.7333 - val_loss: 0.6318 - val_accuracy: 0.6667\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5684 - accuracy: 0.7333 - val_loss: 0.6292 - val_accuracy: 0.6667\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5659 - accuracy: 0.7333 - val_loss: 0.6265 - val_accuracy: 0.6667\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5636 - accuracy: 0.7333 - val_loss: 0.6240 - val_accuracy: 0.6667\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5611 - accuracy: 0.7333 - val_loss: 0.6211 - val_accuracy: 0.6667\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5587 - accuracy: 0.7333 - val_loss: 0.6185 - val_accuracy: 0.7000\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5564 - accuracy: 0.7333 - val_loss: 0.6159 - val_accuracy: 0.7000\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5541 - accuracy: 0.7333 - val_loss: 0.6132 - val_accuracy: 0.7000\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5518 - accuracy: 0.7333 - val_loss: 0.6106 - val_accuracy: 0.7000\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5496 - accuracy: 0.7333 - val_loss: 0.6081 - val_accuracy: 0.7000\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5472 - accuracy: 0.7333 - val_loss: 0.6056 - val_accuracy: 0.7000\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5454 - accuracy: 0.7333 - val_loss: 0.6027 - val_accuracy: 0.7000\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5428 - accuracy: 0.7417 - val_loss: 0.6004 - val_accuracy: 0.7000\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5406 - accuracy: 0.7417 - val_loss: 0.5981 - val_accuracy: 0.7000\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5385 - accuracy: 0.7417 - val_loss: 0.5959 - val_accuracy: 0.7000\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5363 - accuracy: 0.7500 - val_loss: 0.5937 - val_accuracy: 0.7000\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5343 - accuracy: 0.7500 - val_loss: 0.5915 - val_accuracy: 0.7000\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5322 - accuracy: 0.7500 - val_loss: 0.5891 - val_accuracy: 0.7000\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5301 - accuracy: 0.7500 - val_loss: 0.5869 - val_accuracy: 0.7000\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5281 - accuracy: 0.7583 - val_loss: 0.5844 - val_accuracy: 0.7333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5260 - accuracy: 0.7583 - val_loss: 0.5822 - val_accuracy: 0.7333\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5240 - accuracy: 0.7583 - val_loss: 0.5800 - val_accuracy: 0.7333\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5219 - accuracy: 0.7583 - val_loss: 0.5778 - val_accuracy: 0.7333\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5200 - accuracy: 0.7583 - val_loss: 0.5754 - val_accuracy: 0.7667\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5180 - accuracy: 0.7583 - val_loss: 0.5732 - val_accuracy: 0.7667\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5161 - accuracy: 0.7583 - val_loss: 0.5709 - val_accuracy: 0.7667\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5142 - accuracy: 0.7583 - val_loss: 0.5690 - val_accuracy: 0.7667\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5122 - accuracy: 0.7583 - val_loss: 0.5669 - val_accuracy: 0.7667\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5104 - accuracy: 0.7583 - val_loss: 0.5649 - val_accuracy: 0.7667\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5085 - accuracy: 0.7583 - val_loss: 0.5626 - val_accuracy: 0.7667\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5066 - accuracy: 0.7667 - val_loss: 0.5604 - val_accuracy: 0.7667\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5048 - accuracy: 0.7667 - val_loss: 0.5582 - val_accuracy: 0.7667\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5030 - accuracy: 0.7833 - val_loss: 0.5563 - val_accuracy: 0.7667\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5012 - accuracy: 0.7833 - val_loss: 0.5542 - val_accuracy: 0.7667\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4994 - accuracy: 0.7833 - val_loss: 0.5521 - val_accuracy: 0.7667\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7917 - val_loss: 0.5501 - val_accuracy: 0.7667\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4959 - accuracy: 0.7917 - val_loss: 0.5482 - val_accuracy: 0.7667\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4942 - accuracy: 0.7917 - val_loss: 0.5463 - val_accuracy: 0.7667\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4925 - accuracy: 0.7917 - val_loss: 0.5443 - val_accuracy: 0.7667\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4908 - accuracy: 0.7917 - val_loss: 0.5424 - val_accuracy: 0.7667\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4891 - accuracy: 0.7917 - val_loss: 0.5405 - val_accuracy: 0.7667\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4874 - accuracy: 0.8000 - val_loss: 0.5387 - val_accuracy: 0.7667\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4858 - accuracy: 0.8000 - val_loss: 0.5368 - val_accuracy: 0.7667\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4841 - accuracy: 0.8000 - val_loss: 0.5351 - val_accuracy: 0.7667\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4825 - accuracy: 0.8000 - val_loss: 0.5332 - val_accuracy: 0.7667\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4809 - accuracy: 0.8000 - val_loss: 0.5314 - val_accuracy: 0.8000\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4793 - accuracy: 0.8083 - val_loss: 0.5296 - val_accuracy: 0.8000\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4778 - accuracy: 0.8083 - val_loss: 0.5280 - val_accuracy: 0.8000\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4762 - accuracy: 0.8083 - val_loss: 0.5261 - val_accuracy: 0.8000\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4747 - accuracy: 0.8083 - val_loss: 0.5241 - val_accuracy: 0.8333\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4731 - accuracy: 0.8083 - val_loss: 0.5223 - val_accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4717 - accuracy: 0.8083 - val_loss: 0.5204 - val_accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4700 - accuracy: 0.8083 - val_loss: 0.5190 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4685 - accuracy: 0.8083 - val_loss: 0.5174 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4671 - accuracy: 0.8083 - val_loss: 0.5157 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4656 - accuracy: 0.8250 - val_loss: 0.5139 - val_accuracy: 0.8667\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4641 - accuracy: 0.8333 - val_loss: 0.5123 - val_accuracy: 0.8667\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4627 - accuracy: 0.8333 - val_loss: 0.5108 - val_accuracy: 0.8667\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4613 - accuracy: 0.8333 - val_loss: 0.5090 - val_accuracy: 0.8667\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4598 - accuracy: 0.8417 - val_loss: 0.5074 - val_accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4585 - accuracy: 0.8417 - val_loss: 0.5057 - val_accuracy: 0.8667\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4570 - accuracy: 0.8417 - val_loss: 0.5043 - val_accuracy: 0.8667\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4556 - accuracy: 0.8417 - val_loss: 0.5026 - val_accuracy: 0.8667\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4542 - accuracy: 0.8500 - val_loss: 0.5010 - val_accuracy: 0.8667\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4529 - accuracy: 0.8500 - val_loss: 0.4994 - val_accuracy: 0.8667\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4515 - accuracy: 0.8583 - val_loss: 0.4980 - val_accuracy: 0.8667\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4502 - accuracy: 0.8583 - val_loss: 0.4965 - val_accuracy: 0.8667\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4488 - accuracy: 0.8583 - val_loss: 0.4949 - val_accuracy: 0.8667\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4476 - accuracy: 0.8667 - val_loss: 0.4933 - val_accuracy: 0.8667\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4462 - accuracy: 0.8750 - val_loss: 0.4918 - val_accuracy: 0.9000\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4449 - accuracy: 0.8750 - val_loss: 0.4904 - val_accuracy: 0.9000\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4436 - accuracy: 0.8750 - val_loss: 0.4890 - val_accuracy: 0.9000\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.8750 - val_loss: 0.4876 - val_accuracy: 0.9000\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4411 - accuracy: 0.8750 - val_loss: 0.4859 - val_accuracy: 0.9000\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4398 - accuracy: 0.8750 - val_loss: 0.4845 - val_accuracy: 0.9000\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4385 - accuracy: 0.8750 - val_loss: 0.4829 - val_accuracy: 0.9000\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4373 - accuracy: 0.8833 - val_loss: 0.4814 - val_accuracy: 0.9000\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4360 - accuracy: 0.8833 - val_loss: 0.4801 - val_accuracy: 0.9000\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4348 - accuracy: 0.8833 - val_loss: 0.4786 - val_accuracy: 0.9000\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4336 - accuracy: 0.8833 - val_loss: 0.4772 - val_accuracy: 0.9000\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4323 - accuracy: 0.8833 - val_loss: 0.4757 - val_accuracy: 0.9000\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4311 - accuracy: 0.8833 - val_loss: 0.4742 - val_accuracy: 0.9000\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4299 - accuracy: 0.8833 - val_loss: 0.4728 - val_accuracy: 0.9000\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4287 - accuracy: 0.8833 - val_loss: 0.4714 - val_accuracy: 0.9000\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4276 - accuracy: 0.8917 - val_loss: 0.4700 - val_accuracy: 0.9000\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4264 - accuracy: 0.8917 - val_loss: 0.4686 - val_accuracy: 0.9000\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4252 - accuracy: 0.8917 - val_loss: 0.4672 - val_accuracy: 0.9000\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4241 - accuracy: 0.8917 - val_loss: 0.4658 - val_accuracy: 0.9000\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4229 - accuracy: 0.9000 - val_loss: 0.4646 - val_accuracy: 0.9000\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4219 - accuracy: 0.9000 - val_loss: 0.4635 - val_accuracy: 0.9000\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4206 - accuracy: 0.9000 - val_loss: 0.4622 - val_accuracy: 0.9000\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4195 - accuracy: 0.9000 - val_loss: 0.4605 - val_accuracy: 0.9000\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4184 - accuracy: 0.9000 - val_loss: 0.4592 - val_accuracy: 0.9000\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4173 - accuracy: 0.9000 - val_loss: 0.4577 - val_accuracy: 0.9000\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4161 - accuracy: 0.9000 - val_loss: 0.4566 - val_accuracy: 0.9000\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4151 - accuracy: 0.9000 - val_loss: 0.4552 - val_accuracy: 0.9000\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4139 - accuracy: 0.9000 - val_loss: 0.4540 - val_accuracy: 0.9333\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4128 - accuracy: 0.9000 - val_loss: 0.4529 - val_accuracy: 0.9000\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4118 - accuracy: 0.9000 - val_loss: 0.4517 - val_accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4107 - accuracy: 0.9000 - val_loss: 0.4507 - val_accuracy: 0.9000\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.9000 - val_loss: 0.4495 - val_accuracy: 0.9333\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4086 - accuracy: 0.9000 - val_loss: 0.4481 - val_accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4075 - accuracy: 0.9000 - val_loss: 0.4471 - val_accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4065 - accuracy: 0.9083 - val_loss: 0.4458 - val_accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4054 - accuracy: 0.9083 - val_loss: 0.4445 - val_accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4044 - accuracy: 0.9083 - val_loss: 0.4435 - val_accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4034 - accuracy: 0.9083 - val_loss: 0.4422 - val_accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4024 - accuracy: 0.9083 - val_loss: 0.4410 - val_accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4014 - accuracy: 0.9083 - val_loss: 0.4401 - val_accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4003 - accuracy: 0.9083 - val_loss: 0.4388 - val_accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3994 - accuracy: 0.9083 - val_loss: 0.4378 - val_accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3984 - accuracy: 0.9167 - val_loss: 0.4364 - val_accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3973 - accuracy: 0.9167 - val_loss: 0.4352 - val_accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3965 - accuracy: 0.9250 - val_loss: 0.4338 - val_accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3955 - accuracy: 0.9250 - val_loss: 0.4325 - val_accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.9250 - val_loss: 0.4316 - val_accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3934 - accuracy: 0.9250 - val_loss: 0.4304 - val_accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3924 - accuracy: 0.9250 - val_loss: 0.4293 - val_accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3915 - accuracy: 0.9250 - val_loss: 0.4283 - val_accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3904 - accuracy: 0.9250 - val_loss: 0.4271 - val_accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.9250 - val_loss: 0.4261 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff6f01b1e90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train,y=y_train,epochs=300,validation_data=(scaled_X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos o desempenho de nosso Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff6abccc550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff6abc67710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42613890767097473, 0.9666666388511658]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construímos agora um novo Modelo e treinamos ele em todos os dados do *dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)\n",
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0001 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9935 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9877 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.9814 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9757 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9699 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9640 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9587 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9532 - accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9481 - accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9430 - accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9381 - accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9335 - accuracy: 0.3400\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.9289 - accuracy: 0.3467\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.9242 - accuracy: 0.3533\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9199 - accuracy: 0.3733\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9156 - accuracy: 0.3933\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9114 - accuracy: 0.4267\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9072 - accuracy: 0.4400\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9032 - accuracy: 0.4600\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8991 - accuracy: 0.5067\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8950 - accuracy: 0.5333\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8909 - accuracy: 0.5667\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8870 - accuracy: 0.5933\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8832 - accuracy: 0.6067\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8792 - accuracy: 0.6067\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8753 - accuracy: 0.6267\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.6467\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8675 - accuracy: 0.6667\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8637 - accuracy: 0.6667\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8602 - accuracy: 0.6667\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8564 - accuracy: 0.6667\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8531 - accuracy: 0.6667\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8497 - accuracy: 0.6667\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8465 - accuracy: 0.6667\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 0.6667\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8406 - accuracy: 0.6667\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8376 - accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8349 - accuracy: 0.6667\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8322 - accuracy: 0.6667\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8295 - accuracy: 0.6667\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8269 - accuracy: 0.6667\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8244 - accuracy: 0.6667\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8220 - accuracy: 0.6667\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8195 - accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8172 - accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8148 - accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8126 - accuracy: 0.6667\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8104 - accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8080 - accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8058 - accuracy: 0.6667\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8037 - accuracy: 0.6667\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8015 - accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7993 - accuracy: 0.6667\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.7971 - accuracy: 0.6667\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7949 - accuracy: 0.6667\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7928 - accuracy: 0.6667\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7908 - accuracy: 0.6667\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7886 - accuracy: 0.6667\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7865 - accuracy: 0.6667\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7844 - accuracy: 0.6667\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7824 - accuracy: 0.6667\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7803 - accuracy: 0.6667\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7783 - accuracy: 0.6667\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7762 - accuracy: 0.6667\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7742 - accuracy: 0.6667\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7722 - accuracy: 0.6667\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7702 - accuracy: 0.6667\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7682 - accuracy: 0.6667\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7662 - accuracy: 0.6667\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7642 - accuracy: 0.6667\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7622 - accuracy: 0.6667\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7603 - accuracy: 0.6667\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.6667\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7564 - accuracy: 0.6667\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7545 - accuracy: 0.6667\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7526 - accuracy: 0.6667\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7506 - accuracy: 0.6667\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7488 - accuracy: 0.6667\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7469 - accuracy: 0.6667\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7450 - accuracy: 0.6667\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7431 - accuracy: 0.6667\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7413 - accuracy: 0.6667\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7394 - accuracy: 0.6667\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7376 - accuracy: 0.6667\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.6667\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7321 - accuracy: 0.6667\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7303 - accuracy: 0.6667\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7286 - accuracy: 0.6667\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7267 - accuracy: 0.6667\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7249 - accuracy: 0.6667\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7231 - accuracy: 0.6667\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7214 - accuracy: 0.6667\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7196 - accuracy: 0.6667\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.6667\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7162 - accuracy: 0.6667\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7144 - accuracy: 0.6667\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7128 - accuracy: 0.6667\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.6667\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.6667\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.6667\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.7060 - accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7043 - accuracy: 0.6667\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.6667\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7010 - accuracy: 0.6667\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.6667\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.6667\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.6667\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.6667\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.6667\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6849 - accuracy: 0.6667\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.6667\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6819 - accuracy: 0.6667\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.6667\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.6667\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.6667\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6667\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.6733\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6733\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.6733\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6698 - accuracy: 0.6733\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6683 - accuracy: 0.6733\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6733\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.6733\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6638 - accuracy: 0.6733\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.6800\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.6800\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6594 - accuracy: 0.6800\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.6800\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6567 - accuracy: 0.6800\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.6800\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6537 - accuracy: 0.6800\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6800\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6800\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6494 - accuracy: 0.6800\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6867\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6867\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6867\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6438 - accuracy: 0.6867\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6867\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6867\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6398 - accuracy: 0.6867\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6867\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6867\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6867\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6867\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6867\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.6867\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6303 - accuracy: 0.6867\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6867\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6276 - accuracy: 0.6867\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.6867\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6867\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6867\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6867\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6199 - accuracy: 0.6867\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6867\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6867\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6867\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6867\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6127 - accuracy: 0.6933\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.6933\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6933\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6933\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6933\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.6933\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.6036 - accuracy: 0.7000\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.7000\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.7000\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5991 - accuracy: 0.7000\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7000\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.7133\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7133\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.7133\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7133\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.7133\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5879 - accuracy: 0.7200\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7200\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7267\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.7333\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.7333\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7267\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7267\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5767 - accuracy: 0.7400\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7333\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7333\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.7467\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.7467\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7667\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5674 - accuracy: 0.7733\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7800\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7867\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7867\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7867\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5596 - accuracy: 0.7867\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7933\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.7933\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.8000\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5536 - accuracy: 0.8000\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.8067\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.8067\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.8067\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.8067\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.8067\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.8133\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5429 - accuracy: 0.8133\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.8133\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.8133\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.8133\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.8133\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5355 - accuracy: 0.8133\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.8200\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.8267\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.8267\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.8267\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.8267\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.8267\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.8267\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.8400\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.8400\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.8267\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.8333\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.8400\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8400\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.8467\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.8467\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.8600\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5082 - accuracy: 0.8533\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8533\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8600\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8600\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8733\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.8800\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.8733\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8733\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.8800\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8867\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.8800\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8800\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.8800\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.8867\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.8867\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8867\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.8933\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.8867\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.8867\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8867\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8867\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.8867\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.8867\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.8867\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.8933\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.8933\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8933\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.8933\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.9000\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.9000\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.9000\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.9000\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.9000\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9067\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.9067\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.9067\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.9067\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.9000\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.9000\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.9000\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.9067\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.9067\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.9067\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.9067\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.9067\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.9067\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.9067\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.9067\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.9067\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.9067\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.9067\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.9067\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.9067\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.9067\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.9067\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.9133\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.9133\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.9133\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.9133\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.9133\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.9067\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.9133\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.9133\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.9200\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.9267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff6abb4ca10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvamos o modelo para uso futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('iris_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvamos o nosso scaler para uso futoro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos nosso Modelo e o Scaler para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('iris_model.h5')\n",
    "flower_scaler = joblib.load('iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "    \"sepal_length\":5.1,\n",
    "    \"sepal_width\":3.5,\n",
    "    \"petal_length\":1.4,\n",
    "    \"petal_width\":0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model, scaler, sample_json):\n",
    "    \"\"\"\n",
    "    Função return_prediction\n",
    "    Recebe um modelo, um scaler \n",
    "    e um dicionário representando uma amostra\n",
    "    Retorna uma previsão\n",
    "    \"\"\"\n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    classes = np.array(['setosa','versicolor','virginica'])\n",
    "    flower = scaler.transform(flower)\n",
    "    class_index = np.argmax(model.predict(flower), axis=-1)[0]\n",
    "    return classes[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código para Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "flower_model = load_model('iris_model.h5')\n",
    "flower_scaler = joblib.load('iris_scaler.pkl')\n",
    "\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    classes = np.array(['setosa','versicolor','virginica'])\n",
    "    flower = scaler.transform(flower)\n",
    "    class_index = np.argmax(model.predict(flower), axis=-1)[0]\n",
    "    return classes[class_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
